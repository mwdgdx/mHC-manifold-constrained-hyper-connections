# Workflow configuration for `infra_scripts/workflow.sh`.
#
# This file is `source`d by bash. Keep it to simple KEY=VALUE pairs.
# No secrets (no API keys). Prefer W&B credentials via `~/.netrc` on the pod.

############################################
# Platform / Remote Host
############################################

# Preferred: Lium pod identifier (pod name/ID or index from `lium ps`).
# If set, the workflow uses `lium exec/scp` instead of `ssh/scp`.
LIUM_TARGET=""

# Optional fallback: SSH host alias (e.g. from ~/.ssh/config).
OPS_DEFAULT_HOST="lium"

############################################
# Pod Provisioning (optional, Lium)
############################################

# If you want `pod-up` to work, fill these out.
LIUM_POD_NAME="my-gpu-pod"

# If set, this is passed as positional EXECUTOR_ID to `lium up`.
LIUM_EXECUTOR_ID=""

# Otherwise, the workflow uses filters.
LIUM_GPU="RTX3090"
LIUM_COUNT="2"
LIUM_COUNTRY=""
LIUM_PORTS=""

LIUM_TTL="2h"

# Volume attach spec for `lium up`.
# Examples:
# - LIUM_VOLUME="id:<HUID>"
# - LIUM_VOLUME="new:name=my_volume"
LIUM_VOLUME="new:name=my_volume"

# If 1, passes `--yes` to `lium up`.
LIUM_YES="0"

# Path on the pod where the workflow config should be installed.
# This is intended to live on a persistent volume.
REMOTE_ENV_PATH="/mnt/project.env"

############################################
# Remote Layout (pod)
############################################

# Where the repo should live on fast local disk.
OPS_REMOTE_REPO="/root/work/mHC-manifold-constrained-hyper-connections"

# Durable output root (each run writes to ${OPS_REMOTE_OUTPUTS_DIR}/<run_id>/).
OPS_REMOTE_OUTPUTS_DIR="/mnt/pod_artifacts/outputs"

# Durable dataset root (FineWeb10B shards).
DATA_DIR="/mnt/data/fineweb10B"

# Optional durable cache roots.
HF_HOME="/mnt/hf"

############################################
# Workflow Session / Tasks
############################################

# Default tmux session used for tracked tasks (non-sweep long-running actions).
WF_TMUX_SESSION="wf"

# Default timeout for tracked tasks started via `task-run`.
# 0 disables timeouts.
TASK_TIMEOUT_SECS="0"

# Default timeout for each sweep run started by `sweep-start`.
# 0 disables timeouts.
RUN_TIMEOUT_SECS="0"

############################################
# Run Artifact Sync (optional)
############################################

# Where training should write artifacts:
# - durable: write directly to ${OPS_REMOTE_OUTPUTS_DIR}/<run_id>/ (safest)
# - local_sync: write to local disk and continuously rsync into the durable run dir
RUN_OUT_MODE="durable"

# Only used when RUN_OUT_MODE=local_sync.
# Default points at the fast local repo disk.
RUN_OUT_LOCAL_ROOT="${OPS_REMOTE_REPO}/examples/nanogpt/out"

# Only used when RUN_OUT_MODE=local_sync.
# How often to rsync local artifacts into the durable run dir.
SYNC_INTERVAL_SECS="60"

############################################
# Python Environment (remote)
############################################

# Python executable to use on the pod for venv creation and installs.
# If your image provides torch in a non-default python (e.g. conda), point this
# at that python.
REMOTE_PYTHON_BIN="python3"

# If 1, delete and recreate the venv during `checkout`.
VENV_RECREATE="0"

############################################
# Repo Checkout
############################################

# REQUIRED: Git URL for the repo to clone on the pod.
# Examples:
# - REPO_URL="git@github.com:<org>/<repo>.git"
# - REPO_URL="https://github.com/<org>/<repo>.git"
REPO_URL=""

# Choose ONE of:
# - CHECKOUT_BRANCH (recommended for normal runs)
# - CHECKOUT_PR (GitHub PR number; uses `pull/<n>/head` fetch)
CHECKOUT_BRANCH="main"
CHECKOUT_PR=""

# Optional: pin the exact git SHA expected after checkout.
# Useful to guarantee "remote == local" after you push your branch.
EXPECT_GIT_SHA=""

# If 1, `checkout` will hard-reset tracked files in the remote repo before pulling.
# Leave this off by default; prefer fresh pods and a clean checkout.
CHECKOUT_FORCE_CLEAN="0"

############################################
# Bootstrap Helpers (optional)
############################################

# Optional pod bootstrap script that may exist on the persistent volume.
BOOTSTRAP_SCRIPT="/mnt/bootstrap-pod.sh"

# Optional script that writes ~/.netrc for W&B (preferred over exporting WANDB_API_KEY).
WANDB_SETUP_SCRIPT="/mnt/set-wandb-api-key.sh"

# If 1, run WANDB_SETUP_SCRIPT even when SWEEP_WANDB=0.
RUN_WANDB_SETUP="0"

# If 1, the workflow will attempt to install missing prereqs via apt-get.
AUTO_INSTALL_PREREQS="1"
APT_PACKAGES="git tmux rsync curl python3 python3-venv"

# If 1, auto-download minimal FineWeb10B shards when missing.
# Note: if DATA_DIR is under /mnt and /mnt is mounted via s3fs, the workflow will
# stage the download on local disk and then copy completed shards into DATA_DIR.
DOWNLOAD_FINEWEB="0"

############################################
# Sweep Configuration
############################################

# Sweep manifest path (local).
# `sweep-start` uploads this file to `${OPS_REMOTE_OUTPUTS_DIR}/_manifests/sweep-latest.csv`
# and runs the sweep from that remote manifest path (to keep the remote git checkout clean).
# You can generate a starter CSV with: `bash infra_scripts/workflow.sh sweep-csv-template`.
SWEEP_CSV="sweeps/sweep.csv"

# Optional filters.
SWEEP_MATCH=""
SWEEP_START_AT=""
SWEEP_LIMIT=""

# If 1, rerun even if summary.json exists.
SWEEP_FORCE="0"

# Sweep tmux session (single window runs sequential DDP runs).
SWEEP_TMUX_SESSION="sweeps"

# Sweep launcher:
# - Each CSV row is launched with torchrun using *all visible GPUs*.
# - If you want to restrict GPU visibility, set CUDA_VISIBLE_DEVICES (e.g. "0,1,2,3")
#   in your pod environment before starting the sweep.

# W&B controls.
SWEEP_WANDB="0"         # 1=enable, 0=disable
WANDB_PROJECT=""        # optional override
WANDB_GROUP=""          # optional override (if empty, workflow auto-generates)

############################################
# Local Fetch
############################################

LOCAL_ARTIFACTS_DIR="artifacts/pod_logs"
