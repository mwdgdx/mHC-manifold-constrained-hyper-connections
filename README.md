## mHC (Manifold-Constrained Hyper-Connections)

Research implementation of **mHC** (DeepSeek; https://arxiv.org/abs/2512.24880) as a drop-in variant of **Hyper-Connections** (https://arxiv.org/abs/2409.19606).

### What we're building

A runnable PyTorch implementation of the mHC layer update

`x_{l+1} = H_l^{res} x_l + H_l^{post,T} F(H_l^{pre} x_l, W_l)`

with the key constraints:

- `H_res`: **doubly stochastic** (Birkhoff polytope; entries ≥ 0, rows sum to 1, cols sum to 1), via **Sinkhorn-Knopp**.
- `H_pre`, `H_post`: **non-negative** mixing maps.

### Implementation direction

Static per-layer matrices (closest to the paper):
- learn `H_res_logits ∈ R^{s×s}` and project to `H_res` with Sinkhorn
- learn `H_pre_logits`, `H_post_logits` and map to non-negative weights (e.g. softmax)

This is a research prototype aimed at correctness + clarity, not the paper's systems optimizations.

### Running (nanogpt)

Baseline (fineweb10B):

```bash
torchrun --standalone --nproc_per_node=4 --log-dir /tmp/torchrun --redirects 3 --tee 3 examples/nanogpt/train.py examples/nanogpt/config/train_fineweb10B.py
```

Hyper-Connections (fineweb10B):

```bash
torchrun --standalone --nproc_per_node=4 --log-dir /tmp/torchrun --redirects 3 --tee 3 examples/nanogpt/train.py examples/nanogpt/config/train_fineweb10B_hc.py
```

### Acknowledgements

Building on top of `lucidrains/hyper-connections`

### License

MIT